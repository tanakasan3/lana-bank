# Docker, Podman and Tilt
dev-up:
	cd dev && tilt up

dev-down:
	cd dev && tilt down

podman-service-start:
	@./dev/bin/podman-service-start.sh

# ── Container Management ──────────────────────────────────────────────────────────
# The ENGINE_DEFAULT and DOCKER_HOST environment variables are automatically set based on
# available container engines. To force use of podman, set ENGINE_DEFAULT=podman in your environment.
# The podman-* targets below are Linux-only and used for manual podman service setup.

check-code-rust: generate-default-config
	git diff --exit-code dev/lana.default.yml
	SQLX_OFFLINE=true cargo fmt --check --all
	SQLX_OFFLINE=true cargo check
	SQLX_OFFLINE=true cargo clippy --all-features --all-targets
	SQLX_OFFLINE=true cargo audit
	cargo deny check --hide-inclusion-graph
	cargo machete

check-custom-lints:
	cargo run -p custom-lints


# ── Test Targets ───────────────────────────────────────────────────────────────────

next-watch:
	cargo watch -s 'cargo nextest run'

clean-deps:
	./dev/bin/clean-deps.sh

start-deps:
	./dev/bin/docker-compose-up.sh

# Rust backend
setup-db:
	cd lana/app && cargo sqlx migrate run

sqlx-prepare:
	cargo sqlx prepare --workspace

reset-deps: clean-deps start-deps setup-db

gotenberg-up:
	docker compose -f docker-compose.gotenberg.yml up -d gotenberg

gotenberg-down:
	docker compose -f docker-compose.gotenberg.yml down

run-server-normal:
	cargo run --features mock-custodian,sumsub-testing --bin lana-cli -- --config ./bats/lana-normal.yml > >(tee .e2e-logs) 2>&1

run-server:
	cargo run --features mock-custodian,sumsub-testing --bin lana-cli -- --config ./bats/lana.yml > >(tee .e2e-logs) 2>&1

run-server-nix:
	nix run . -- --config ./bats/lana.yml 2>&1 | tee .e2e-logs

run-server-with-bootstrap:
	cargo run --all-features --bin lana-cli -- --config ./bats/lana-bootstrap.yml | tee .e2e-logs

check-code: check-code-apps
	nix flake check

update-schemas:
	SQLX_OFFLINE=true cargo run --package entity-rollups --all-features -- update-schemas --force-recreate

e2e: clean-deps start-deps
	bats -t bats

# Cargo alternative for faster compilation during development
sdl-rust:
	SQLX_OFFLINE=true cargo run --bin write_sdl > lana/admin-server/src/graphql/schema.graphql
	SQLX_OFFLINE=true cargo run --bin write_customer_sdl > lana/customer-server/src/graphql/schema.graphql

# Generate default configuration file
generate-default-config:
	SQLX_OFFLINE=true cargo run -p lana-cli --all-features -- dump-default-config > dev/lana.default.yml

sdl-js:
	cd apps/admin-panel && pnpm install && pnpm codegen
	cd apps/customer-portal && pnpm install && pnpm codegen

generate-translation-labels:
	SQLX_OFFLINE=true cargo run --bin write_translation_labels

sdl: sdl-rust sdl-js generate-translation-labels

# Frontend Apps
check-code-apps: sdl-js check-code-apps-admin-panel check-code-apps-customer-portal
	git diff --exit-code apps/admin-panel/lib/graphql/generated/
	git diff --exit-code apps/customer-portal/lib/graphql/generated/

start-admin:
	cd apps/admin-panel && pnpm install --frozen-lockfile && pnpm dev

start-customer-portal:
	cd apps/customer-portal && pnpm install --frozen-lockfile && pnpm dev

check-code-apps-admin-panel:
	cd apps/admin-panel && pnpm install --frozen-lockfile && pnpm lint && pnpm tsc-check && pnpm build

check-code-apps-customer-portal:
	cd apps/customer-portal && pnpm install --frozen-lockfile && pnpm lint && pnpm tsc-check && pnpm build

build-storybook-admin-panel:
	cd apps/admin-panel && pnpm install --frozen-lockfile && pnpm run build-storybook

# ── Documentation ─────────────────────────────────────────────────────────────────

# Generate JSON schema for public domain events
update-public-event-schemas:
	SQLX_OFFLINE=true cargo run --package public-events-schema --features json-schema

# Generate all autogenerated docs for Docusaurus (API docs from GraphQL schemas + domain events)
docs-autogenerate: update-public-event-schemas
	cd docs-site && npm install && npm run generate-api-docs && npm run generate-events-docs

# Generate docs and add TODO placeholders for new operations
prep-docs:
	cd docs-site && \
		npm run generate-api-docs && \
		npm run generate-versioned-api-docs

# Validate docs-site API descriptions (mirrors CI workflow)
check-docs: prep-docs
	cd docs-site && npm run validate-api-descriptions
	cd docs-site && git checkout scripts/api-descriptions.json scripts/api-descriptions.es.json

test-cypress-in-ci:
	@echo "--- Starting Cypress Tests ---"
	@echo "Working directory: $(shell pwd)"
	@echo "Node version: $(shell node --version 2>/dev/null || echo 'Node not found')"
	@echo "Pnpm version: $(shell pnpm --version 2>/dev/null || echo 'Pnpm not found')"
	@echo "Checking if services are running..."
	@echo "--- Service Health Checks ---"
	@echo "Core server status:"
	@curl -s -o /dev/null -w "Response code: %{response_code}\n" http://localhost:5253/health || echo "Core server health check failed"
	@echo "GraphQL endpoint status:"
	@curl -s -o /dev/null -w "Response code: %{response_code}\n" http://localhost:5253/graphql || echo "GraphQL endpoint check failed"
	@echo "Admin panel status:"
	@curl -s -o /dev/null -w "Response code: %{response_code}\n" http://localhost:3001/api/health || echo "Admin panel direct check failed"
	@curl -s -o /dev/null -w "Response code: %{response_code}\n" http://admin.localhost:4455/api/health || echo "Admin panel via proxy failed"
	@echo "Database connectivity check:"
	@echo "Container status:"
	@$${ENGINE_DEFAULT:-docker} ps --filter "label=com.docker.compose.project=lana-bank" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" || echo "Failed to check container status"
	@echo "--- End Health Checks ---"
	@echo "--- Running Cypress Tests ---"
	@echo "Installing Cypress binary if missing..."
	cd apps/admin-panel && pnpm exec cypress install
	cd apps/admin-panel && CI=true pnpm cypress:run-headless

# Dagster
dagster-up:
	docker compose -f docker-compose.dagster.yml up -d --build

dagster-stop:
	docker compose -f docker-compose.dagster.yml stop

dagster-down:
	docker compose -f docker-compose.dagster.yml down

# Dagster asset materialization - run in correct dependency order
# 1. EL raw tables first (from lana-core → DW)
# 2. dbt seeds (reference data)
# 3. dbt models (transforms on raw tables)

dagster-materialize-el:
	@echo "Materializing EL raw tables (lana → DW)..."
	docker compose -f docker-compose.dagster.yml exec -T dagster_webserver \
		dagster job execute -j lana_to_dw_el -w workspace.yaml

dagster-materialize-dbt-seeds:
	@echo "Materializing dbt seeds..."
	docker compose -f docker-compose.dagster.yml exec -T dagster_webserver \
		dagster job execute -j dbt_seeds_job -w workspace.yaml

dagster-materialize-dbt-models:
	@echo "Materializing dbt models..."
	docker compose -f docker-compose.dagster.yml exec -T dagster_webserver \
		dagster job execute -j dbt_models_job -w workspace.yaml

dagster-materialize-bitfinex:
	@echo "Materializing Bitfinex EL assets..."
	docker compose -f docker-compose.dagster.yml exec -T dagster_webserver \
		dagster job execute -j bitfinex_ticker_el -w workspace.yaml
	docker compose -f docker-compose.dagster.yml exec -T dagster_webserver \
		dagster job execute -j bitfinex_trades_el -w workspace.yaml
	docker compose -f docker-compose.dagster.yml exec -T dagster_webserver \
		dagster job execute -j bitfinex_order_book_el -w workspace.yaml

# Full materialization in dependency order (cold start)
dagster-materialize-all: dagster-materialize-el dagster-materialize-dbt-seeds dagster-materialize-dbt-models
	@echo "All assets materialized successfully."

# Quick refresh: just EL + dbt models (skip seeds if already loaded)
dagster-refresh: dagster-materialize-el dagster-materialize-dbt-models
	@echo "Refresh complete."

# ── Dagster with Postgres DW (local dev) ──────────────────────────────────────
# Use these targets for local development with Postgres instead of BigQuery

dagster-postgres-up:
	docker compose -f docker-compose.dagster-postgres.yml up -d --build

dagster-postgres-stop:
	docker compose -f docker-compose.dagster-postgres.yml stop

dagster-postgres-down:
	docker compose -f docker-compose.dagster-postgres.yml down

dagster-postgres-down-clean:
	docker compose -f docker-compose.dagster-postgres.yml down -v

dagster-postgres-logs:
	docker compose -f docker-compose.dagster-postgres.yml logs -f

# Asset materialization for Postgres DW target
dagster-postgres-materialize-el:
	@echo "Materializing EL raw tables (lana → Postgres DW)..."
	docker compose -f docker-compose.dagster-postgres.yml exec -T dagster_webserver \
		dagster job execute -j lana_to_dw_el -w workspace.yaml

dagster-postgres-materialize-dbt-seeds:
	@echo "Materializing dbt seeds..."
	docker compose -f docker-compose.dagster-postgres.yml exec -T dagster_webserver \
		dagster job execute -j dbt_seeds_job -w workspace.yaml

dagster-postgres-materialize-dbt-models:
	@echo "Materializing dbt models..."
	docker compose -f docker-compose.dagster-postgres.yml exec -T dagster_webserver \
		dagster job execute -j dbt_models_job -w workspace.yaml

# Full materialization in dependency order (cold start) - Postgres
dagster-postgres-materialize-all: dagster-postgres-materialize-el dagster-postgres-materialize-dbt-seeds dagster-postgres-materialize-dbt-models
	@echo "All assets materialized successfully (Postgres DW)."

# Quick refresh for Postgres DW
dagster-postgres-refresh: dagster-postgres-materialize-el dagster-postgres-materialize-dbt-models
	@echo "Refresh complete (Postgres DW)."

# Connect to Postgres DW for debugging
dagster-postgres-psql:
	docker compose -f docker-compose.dagster-postgres.yml exec lana-dw-postgres \
		psql -U postgres -d lana_dw

# Usage: make dbt ARGS="run -s my_model"
dbt:
	docker compose -f docker-compose.dagster.yml run --rm --no-deps \
	  --user "$$(id -u):$$(id -g)" \
	  -e HOME=/tmp \
	  -e DBT_PROFILES_DIR=/lana-dw/src/dbt_lana_dw \
	  -v "$$(pwd)/dagster/src/dbt_lana_dw:/lana-dw/src/dbt_lana_dw" \
	  --workdir /lana-dw/src/dbt_lana_dw \
	  dagster-code-location-lana-dw \
	  dbt $(ARGS)

dagster-fmt:
	@bash -c '\
black_status=0; \
black dagster/src || black_status=$$?; \
isort_status=0; \
isort dagster/src || isort_status=$$?; \
sqlfmt_status=0; \
sqlfmt dagster/src/dbt_lana_dw/models || sqlfmt_status=$$?; \
if [[ $$black_status -ne 0 || $$isort_status -ne 0 || $$sqlfmt_status -ne 0 ]]; then exit 1; fi \
'

dagster-fmt-check:
	@bash -c '\
black_status=0; \
black --check --diff dagster/src || black_status=$$?; \
isort_status=0; \
isort --check-only dagster/src || isort_status=$$?; \
sqlfmt_status=0; \
sqlfmt --check dagster/src/dbt_lana_dw/models || sqlfmt_status=$$?; \
if [[ $$black_status -ne 0 || $$isort_status -ne 0 || $$sqlfmt_status -ne 0 ]]; then exit 1; fi \
'

# Dagster EL writes into a different BQ dataset than dbt. This empties that dataset.
bq-drop-dagster-landing:
	bq ls -n 100000 --project_id=$(DBT_BIGQUERY_PROJECT) $(TARGET_BIGQUERY_DATASET) | awk 'NR>2 {print $$1}' | xargs -P 32 -n1 -I{} bash -c 'echo "Deleting: $(DBT_BIGQUERY_PROJECT):$(TARGET_BIGQUERY_DATASET).{}"; bq rm -f -t $(DBT_BIGQUERY_PROJECT):$(TARGET_BIGQUERY_DATASET).{}'

bq-drop-dagster-dbt:
	bq ls -n 100000 --project_id=$(DBT_BIGQUERY_PROJECT) $(DBT_BIGQUERY_DATASET) | awk 'NR>2 {print $$1}' | xargs -P 32 -n1 -I{} bash -c 'echo "Deleting: $(DBT_BIGQUERY_PROJECT):$(DBT_BIGQUERY_DATASET).{}"; bq rm -f -t $(DBT_BIGQUERY_PROJECT):$(DBT_BIGQUERY_DATASET).{}'

# misc
sumsub-webhook-test: # add https://xxx.trycloudflare.com/webhook/sumsub to test integration with sumsub
	cloudflared tunnel --url http://localhost:5253

tilt-in-ci:
	./dev/bin/tilt-ci.sh

start-cypress-stack:
	./dev/bin/start-cypress-stack.sh

stop-cypress-stack:
	./dev/bin/stop-cypress-stack.sh

# Default (nix-based) test in CI
test-in-ci: start-deps setup-db
	nix build .#test-in-ci -L --option sandbox false

# Cargo alternative for faster compilation during development
test-in-ci-cargo: start-deps setup-db
	cargo nextest run --verbose --locked

build-x86_64-unknown-linux-musl-release:
	SQLX_OFFLINE=true cargo build --release --all-features --locked --bin lana-cli --target x86_64-unknown-linux-musl

auth-kcadm:
	kcadm.sh config credentials --server "$$KC_URL" --realm "$$REALM" --user "$$ADMIN_USER" --password "$$ADMIN_PASS"

### this is what is passed on to the server
auth-secret:
	source <(./dev/keycloak/create-client-local-dev.sh --emit-env)

### token is fetched from the server using the client secret
auth-token:
	curl -s -X POST "$$KC_URL/realms/$$KC_REALM/protocol/openid-connect/token" \
		-d grant_type=client_credentials \
		-d client_id="$$KC_CLIENT_ID" \
		-d client_secret="$$KC_CLIENT_SECRET" | jq -r .access_token

create-user:
	./dev/keycloak/create-user.sh

docs-serve:
	cd docs-site && npm run start

# Honeycomb dashboards
honeycomb-init:
	cd tf/honeycomb && tofu init

honeycomb-plan:
	cd tf/honeycomb && tofu plan

honeycomb-apply:
	cd tf/honeycomb && tofu apply -auto-approve

honeycomb-destroy:
	cd tf/honeycomb && tofu destroy
